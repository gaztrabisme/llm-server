# S006 E2: KLD base logits — Q8_0 model, small context for manageable logit file
# 512 ctx × 80 chunks = ~40K tokens × 248K vocab × 2 bytes ≈ ~19 GiB logit file
LLAMA_ARG_MODEL=/models/Qwen3.5-35B-A3B-Q8_0.gguf
LLAMA_ARG_CTX_SIZE=512
LLAMA_ARG_N_GPU_LAYERS=999
LLAMA_ARG_OVERRIDE_TENSOR=exps=CPU
LLAMA_ARG_FLASH_ATTN=true
LLAMA_ARG_THREADS=20
LLAMA_ARG_BATCH_SIZE=512
LLAMA_ARG_UBATCH_SIZE=512
LLAMA_ARG_NO_MMAP=true
LLAMA_ARG_CACHE_TYPE_K=q8_0
LLAMA_ARG_CACHE_TYPE_V=q8_0
