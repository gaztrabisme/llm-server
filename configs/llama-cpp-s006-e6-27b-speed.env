# S006 E6: Qwen3.5-27B Q4_K_M — speed benchmark
# Dense model — doesn't quite fit on 16 GB VRAM, needs --fit to split
# 54/65 layers on GPU with small context, fewer with larger context
LLAMA_ARG_MODEL=/models/Qwen3.5-27B-Q4_K_M.gguf
LLAMA_ARG_CTX_SIZE=8192
LLAMA_ARG_FIT=true
LLAMA_ARG_FLASH_ATTN=true
LLAMA_ARG_THREADS=20
LLAMA_ARG_NO_MMAP=true
LLAMA_ARG_JINJA=true
LLAMA_ARG_HOST=0.0.0.0
LLAMA_ARG_PORT=8080
LLAMA_ARG_CACHE_TYPE_K=q8_0
LLAMA_ARG_CACHE_TYPE_V=q8_0
