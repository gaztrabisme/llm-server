# ik_llama.cpp — Baseline configuration (B1)
# Same as mainline baseline — no ik-specific flags
LLAMA_ARG_MODEL=/models/Qwen3-Next-80B-A3B-Instruct-Q8_0.gguf
LLAMA_ARG_CTX_SIZE=32768
LLAMA_ARG_N_GPU_LAYERS=999
LLAMA_ARG_OVERRIDE_TENSOR=exps=CPU
LLAMA_ARG_FLASH_ATTN=true
LLAMA_ARG_THREADS=16
# NOTE: -b 4096 -ub 4096 causes SIGSEGV in ik_llama.cpp with this model
# Using defaults (2048/512) which work correctly
#LLAMA_ARG_BATCH_SIZE=4096
#LLAMA_ARG_UBATCH_SIZE=4096
LLAMA_ARG_NO_MMAP=true
LLAMA_ARG_JINJA=true
LLAMA_ARG_HOST=0.0.0.0
LLAMA_ARG_PORT=8080
