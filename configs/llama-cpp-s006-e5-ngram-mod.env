# S006 E5: Speculative decoding — ngram-mod (MoE-optimized, longer drafts)
# Based on fit-nobatch winner config from E4
# Docs: "MoEs require long drafts" — use m=64 for longer speculation
LLAMA_ARG_MODEL=/models/Qwen3.5-35B-A3B-Q4_K_M.gguf
LLAMA_ARG_CTX_SIZE=65536
LLAMA_ARG_FIT=true
LLAMA_ARG_FLASH_ATTN=true
LLAMA_ARG_THREADS=20
LLAMA_ARG_NO_MMAP=true
LLAMA_ARG_JINJA=true
LLAMA_ARG_HOST=0.0.0.0
LLAMA_ARG_PORT=8080
LLAMA_ARG_CACHE_TYPE_K=q8_0
LLAMA_ARG_CACHE_TYPE_V=q8_0
LLAMA_ARG_SPEC_TYPE=ngram-mod
LLAMA_ARG_SPEC_NGRAM_M=64
